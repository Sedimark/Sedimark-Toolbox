{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqp import (\n",
    "    AnomalyDetectionModule,\n",
    " \n",
    ")\n",
    "from dqp.data_loaders import load_tods_yahoo, load_egm, load_santander_statuses, load_fv, load_egm2\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from dqp.core import DataSource\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from scipy.io import loadmat\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e3730-a076-4866-b756-dad3a919ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYCARET_CUSTOM_LOGGING_LEVEL\"] = \"CRITICAL\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a607bf1",
   "metadata": {},
   "source": [
    "# Anomaly detection\n",
    "\n",
    "The Anomaly detection module presents a wrapper around algorithms from the libraries `pycaret`, `scikit-learn` and `pyod`. \n",
    "Models starting with `SK_` are from scikit-learn, those starting with `pyod` are from pyod, the rest are from pycaret.\n",
    " \n",
    "In addition, a few methods have been included from the `pythresh` library for thresholding anomaly scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ee5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The following Anomaly Detection methods are supported\")\n",
    "print(AnomalyDetectionModule.list_available_methods(),\"\\n\\n\")\n",
    "print(\"The following automatic thresholding methods are supported\")\n",
    "print(AnomalyDetectionModule._list_available_thresholds())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e0637-8a2b-4c35-baf2-67066dfcb99d",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_egm(\"./datasets/egm/\")\n",
    "# _,_, data = load_fv(\"./datasets/fv/\")\n",
    "# data= load_santander_statuses(\"./datasets/uc/dataset_SDR_example.jsonld\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8de17",
   "metadata": {},
   "source": [
    "## Defining the configuration\n",
    "\n",
    "The main parameters are:\n",
    "1) `model` (the OD method)\n",
    "\n",
    "2) `data_type` - time-series or tabular. (currently only time-series is supported!!)\n",
    "\n",
    "3) `processing_options` - Either describe/remove - whether to anotate the data with anomaly scores, or to remove the detected anomalies from the returned dataset.\n",
    "\n",
    "4) `model_config` - Internal hyperparameters for the OD model (e.g lr, training epochs etc). \n",
    "\n",
    "5) The model also includes `threshold_type` and `threshold_parameters`. These are important for determining how many anomalies will be labelled/removed from the dataset. The simplest approach to use `contamination` and assume that the percentage of outliers in the dataset is known a priori.\n",
    "6) The model can also use automatic threshold calculation using pythresh. To do that use one of the pythresh models in the `threshold_type` and don't use any threshold parameters, i.e. \"threshold_tye\": `AUCP`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \n",
    "    \"model\" : 'pyod_mcd',\n",
    "    \"processing_options\":'describe',\n",
    "    \"model_config\" : {\n",
    "        # 'threshold_type':'contamination', 'threshold_parameters':{'contamination':0.005},\n",
    "        'threshold_type':'AUCP', \n",
    "    },\n",
    "    \"data_type\":'tabular'\n",
    "    # \"data_type\":'time-series'\n",
    "    \n",
    "}\n",
    "\n",
    "module = AnomalyDetectionModule(**config)\n",
    "result = module.process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "result._df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291763a1",
   "metadata": {},
   "source": [
    "## Evaluating the results \n",
    "\n",
    "Without any ground truth, and not being weather experts, it is quite difficult for us to know if it is working or not :(\n",
    "\n",
    "We can see below that quite a few of the labelled anomalies correspond to spikes in the data - but this could just be perfectly normal weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181062d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df=result._df\n",
    "for col in ['illuminance', 'precipitation', 'irradiance', 'windspeedgust', 'humidity', 'temperature']:\n",
    "# for col in ['battery', 'speed', 'location-x', 'location-y']:\n",
    "    \n",
    "    plt.plot(np.arange(len(df[col])), df[col])\n",
    "    plt.scatter(np.arange(len(df[col]))[df['_is_anomaly']], df[col][df['_is_anomaly']],c='red')\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03554b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c678c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
